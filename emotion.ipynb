{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe2c39c1",
   "metadata": {},
   "source": [
    "Emotion Recognition\n",
    "=====\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b421da0",
   "metadata": {},
   "source": [
    "- 사람의 음성/시각정보등을 통해서 감정을 인식하는 과정\n",
    "\n",
    "- 대표적인 모델은 CNN based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd32682",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from typing import Union\n",
    "from torch.nn.modules.pooling import AdaptiveAvgPool2d\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93396304-0f15-420b-84ac-63a87ddd2a90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fix the seed\n",
    "def seed_set(s : int = 42) -> None:\n",
    "  torch.manual_seed(s)\n",
    "  np.random.seed(s)\n",
    "  random.seed(s)\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "  torch.backends.cudnn.benchmark = False\n",
    "\n",
    "random_seed = 41\n",
    "seed_set(random_seed)\n",
    "\n",
    "# CUDA device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a5f171",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"halo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f754257",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c888e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### RAVDESS "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc71d946",
   "metadata": {},
   "source": [
    "[Download](https://zenodo.org/records/1188976)\n",
    "\n",
    "각 오디오 파일마다 의미에 따른 고유의 번호로 구성되어져 있음 (예ㅣ03-01-02-01-01-01-24)\n",
    "\n",
    "- 양식 (01 = full-AV, 02 = video-only, 03 = audio-only) - 주어진 데이터셋의 경우 **03**에 해당\n",
    "    - 보컬 채널 (01 = Speech, 02 = Song) - 주어진 데이터셋의 경우 **01**에 해당\n",
    "\n",
    "\n",
    "- 감정표현 (01 = Neutral, 02 = Calm, 03 = Happy,  04 = Sad, 05 = Angry, 06 = Fearful, 07 = Disgust, 08 = Surprised)\n",
    "    - 총 1440개의 데이터 샘플 존재 (192 * 7 + 96 * 1 = 1440)\n",
    " \n",
    "\n",
    "\n",
    "- 감정의 강함정도 (01 = Normal, 02 = Strong) - Neutral을 제외한 각 감정표현마다 존재\n",
    "\n",
    "- 문장 (01 = “Kids are talking by the door”, 02 = “Dogs are sitting by the door”)\n",
    "\n",
    " \n",
    "\n",
    "- 반복 (01 = “1st”, 02 = “2nd”) \n",
    "\n",
    " \n",
    "\n",
    "- 배우(01 ~ 24) - 여성배우는 짝수, 남성배우는 홀수로 구분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b8667f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ravdess_path = \"/home/mllab/jhson/dann_ser/RAVDESS\"\n",
    "generated_ravdess_path = \"/home/mllab/dchung/dataset/ravdess-hifi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25d29d9a-e18a-4d49-a6fc-2a8c847ca820",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emotions = {'01' : 'Neutral', '02' : 'Calm', '03' : 'Happy',  '04' : 'Sad',\n",
    "              '05' : 'Angry', '06' : 'Fearful', '07' : 'Disgust', '08' : 'Surprised'}\n",
    "\n",
    "level = {'01' : 'Normal', '02' : 'Strong'}\n",
    "\n",
    "statement = {'01' : 'Kids are talking by the door' , '02' : 'Dogs are sitting by the door'}\n",
    "\n",
    "invert_emotions = dict(zip(emotions.values(), emotions.keys()))\n",
    "\n",
    "def gender_classifier(x : int) -> bool:\n",
    "  x = int(x)\n",
    "  if (x % 2 == 0):\n",
    "    return \"Female\"\n",
    "  return \"Male\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed4ed873-ec25-4acb-b0ef-672dae0ca278",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rav_load() returns pandas dataframe processing the given directory\n",
    "def rav_load(dir : str) -> pd.DataFrame:\n",
    "    emotion = []\n",
    "    intensity = []\n",
    "    path = []\n",
    "    sentence = []\n",
    "    id = []\n",
    "\n",
    "    for dirname, _, filenames in os.walk(dir):\n",
    "      for filename in filenames:\n",
    "        if \".npy\" in filename:\n",
    "            continue\n",
    "        path.append(os.path.join(dirname, filename))\n",
    "        Sequence = filename.split('-')\n",
    "        emotion.append(Sequence[2])\n",
    "        intensity.append(Sequence[3])\n",
    "        sentence.append(Sequence[4])\n",
    "        id.append(Sequence[6].split('.')[0])\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'ID' : id,\n",
    "        'Emotion' : emotion,\n",
    "        'Intensity' : intensity,\n",
    "        'Statement' : sentence,\n",
    "        'Path' : path\n",
    "        })\n",
    "\n",
    "    df['Emotion'] = df['Emotion'].map(emotions)\n",
    "    df['Intensity'] = df['Intensity'].map(level)\n",
    "    df['Statement'] = df['Statement'].map(statement)\n",
    "    df['Gender'] = df['ID'].apply(lambda x : gender_classifier(x))\n",
    "    return df\n",
    "\n",
    "df = rav_load(ravdess_path)\n",
    "generated_df = rav_load(generated_ravdess_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5db8744d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Intensity</th>\n",
       "      <th>Statement</th>\n",
       "      <th>Path</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>Calm</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Kids are talking by the door</td>\n",
       "      <td>/home/mllab/jhson/dann_ser/RAVDESS/Actor_22/03...</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>Happy</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Kids are talking by the door</td>\n",
       "      <td>/home/mllab/jhson/dann_ser/RAVDESS/Actor_22/03...</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>Surprised</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Dogs are sitting by the door</td>\n",
       "      <td>/home/mllab/jhson/dann_ser/RAVDESS/Actor_22/03...</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>Sad</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Kids are talking by the door</td>\n",
       "      <td>/home/mllab/jhson/dann_ser/RAVDESS/Actor_22/03...</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>Surprised</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Kids are talking by the door</td>\n",
       "      <td>/home/mllab/jhson/dann_ser/RAVDESS/Actor_22/03...</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID    Emotion Intensity                     Statement  \\\n",
       "0  22       Calm    Normal  Kids are talking by the door   \n",
       "1  22      Happy    Normal  Kids are talking by the door   \n",
       "2  22  Surprised    Strong  Dogs are sitting by the door   \n",
       "3  22        Sad    Strong  Kids are talking by the door   \n",
       "4  22  Surprised    Strong  Kids are talking by the door   \n",
       "\n",
       "                                                Path  Gender  \n",
       "0  /home/mllab/jhson/dann_ser/RAVDESS/Actor_22/03...  Female  \n",
       "1  /home/mllab/jhson/dann_ser/RAVDESS/Actor_22/03...  Female  \n",
       "2  /home/mllab/jhson/dann_ser/RAVDESS/Actor_22/03...  Female  \n",
       "3  /home/mllab/jhson/dann_ser/RAVDESS/Actor_22/03...  Female  \n",
       "4  /home/mllab/jhson/dann_ser/RAVDESS/Actor_22/03...  Female  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f43b493f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Intensity</th>\n",
       "      <th>Statement</th>\n",
       "      <th>Path</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>Calm</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Kids are talking by the door</td>\n",
       "      <td>/home/mllab/dchung/dataset/ravdess-hifi/Actor_...</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>Happy</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Kids are talking by the door</td>\n",
       "      <td>/home/mllab/dchung/dataset/ravdess-hifi/Actor_...</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>Surprised</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Dogs are sitting by the door</td>\n",
       "      <td>/home/mllab/dchung/dataset/ravdess-hifi/Actor_...</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>Sad</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Kids are talking by the door</td>\n",
       "      <td>/home/mllab/dchung/dataset/ravdess-hifi/Actor_...</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>Surprised</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Kids are talking by the door</td>\n",
       "      <td>/home/mllab/dchung/dataset/ravdess-hifi/Actor_...</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID    Emotion Intensity                     Statement  \\\n",
       "0  22       Calm    Normal  Kids are talking by the door   \n",
       "1  22      Happy    Normal  Kids are talking by the door   \n",
       "2  22  Surprised    Strong  Dogs are sitting by the door   \n",
       "3  22        Sad    Strong  Kids are talking by the door   \n",
       "4  22  Surprised    Strong  Kids are talking by the door   \n",
       "\n",
       "                                                Path  Gender  \n",
       "0  /home/mllab/dchung/dataset/ravdess-hifi/Actor_...  Female  \n",
       "1  /home/mllab/dchung/dataset/ravdess-hifi/Actor_...  Female  \n",
       "2  /home/mllab/dchung/dataset/ravdess-hifi/Actor_...  Female  \n",
       "3  /home/mllab/dchung/dataset/ravdess-hifi/Actor_...  Female  \n",
       "4  /home/mllab/dchung/dataset/ravdess-hifi/Actor_...  Female  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56701ffc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### TESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33fe238a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tor_load(str) returns pandas dataframe processing the given directory\n",
    "def tor_load(dir : str) -> pd.DataFrame:\n",
    "    emotion = []\n",
    "    path = []\n",
    "\n",
    "    emotions_To = {'neutral' : 1, 'happy' : 2, 'sad': 3, 'angry' : 4, 'fear' : 5, 'disgust' : 6, 'ps' : 7}\n",
    "\n",
    "    for dirname, _, filenames in os.walk(dir):\n",
    "      for filename in filenames:\n",
    "        path.append(os.path.join(dirname, filename))\n",
    "        Sequence = filename.split('_')\n",
    "        Sequence = Sequence[2].split('.')\n",
    "        emotion.append(Sequence[0])\n",
    "\n",
    "\n",
    "\n",
    "    df = pd.DataFrame({'Emotion' : emotion, 'Path' : path})\n",
    "    df['Emotion'] = df['Emotion'].map(emotions_To)\n",
    "    \n",
    "    return df\n",
    "\n",
    "tor_df = tor_load(\"/home/mllab/dchung/dataset/TESS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fd160d4-7ce6-42ff-9fd0-22f246904462",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>/home/mllab/dchung/dataset/TESS/YAF_neutral/YA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>/home/mllab/dchung/dataset/TESS/YAF_neutral/YA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>/home/mllab/dchung/dataset/TESS/YAF_neutral/YA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>/home/mllab/dchung/dataset/TESS/YAF_neutral/YA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>/home/mllab/dchung/dataset/TESS/YAF_neutral/YA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotion                                               Path\n",
       "0        1  /home/mllab/dchung/dataset/TESS/YAF_neutral/YA...\n",
       "1        1  /home/mllab/dchung/dataset/TESS/YAF_neutral/YA...\n",
       "2        1  /home/mllab/dchung/dataset/TESS/YAF_neutral/YA...\n",
       "3        1  /home/mllab/dchung/dataset/TESS/YAF_neutral/YA...\n",
       "4        1  /home/mllab/dchung/dataset/TESS/YAF_neutral/YA..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tor_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b53dbd0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### AudioUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d49d13",
   "metadata": {},
   "source": [
    "**특징**\n",
    "- Spectrogram관련 처리 라이브러리는 librosa 사용\n",
    "\n",
    "**If applicable**\n",
    "\n",
    "- [0 - 1] 사이로 Clipping\n",
    "\n",
    "- (128, 420)으로 제로 패딩 처리 \n",
    "\n",
    "- (S : original log mel, delta S, delta of delta of S)로 3채널 구성 : [링크](https://wiki.aalto.fi/display/ITSP/Deltas+and+Delta-deltas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5d3caf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# normalize_mel() normalizes a tensor of log mel-spectrogram\n",
    "def normalize_mel(S : torch.Tensor) -> torch.Tensor:\n",
    "    min_level_db= -80\n",
    "    return torch.clip((S-min_level_db)/-min_level_db, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adf1594d-8597-4251-9c63-e3e80f10a647",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mel_spec() returns a log mel-spectrogram\n",
    "def mel_spec(path : str, padding : bool = False) -> Union[np.ndarray, torch.Tensor]:\n",
    "  y, sr = librosa.load(path, sr = 48000)\n",
    "  S = librosa.feature.melspectrogram(y = y, n_fft = 2048, hop_length = 480, sr = sr, win_length = 1920)\n",
    "  logS = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "  if (padding):\n",
    "     logS = torch.from_numpy(logS)\n",
    "     logS = normalize_mel(logS)\n",
    "     desired_shape = (128, 420)\n",
    "     padding_size = desired_shape[1] - logS.shape[1]\n",
    "     logS = torch.nn.functional.pad(logS, (0, padding_size))\n",
    "     return logS.unsqueeze(0)\n",
    "     \n",
    "  return  logS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5672849b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# multi_mel_spec() returns a log-mel spectrogram composed of three channels\n",
    "def multi_mel_spec(path : str) -> torch.Tensor:\n",
    "  y, sr = librosa.load(path, sr = 48000)\n",
    "  S = librosa.feature.melspectrogram(y = y, n_fft = 2048, hop_length = 480, sr = sr, win_length = 1920)\n",
    "\n",
    "  # 3-Log-Mel\n",
    "  logS = librosa.power_to_db(S, ref=np.max)\n",
    "  logS_delta = librosa.feature.delta(logS)\n",
    "  logS_ddelta = librosa.feature.delta(logS_delta)\n",
    "\n",
    "  # Clipping\n",
    "  logS = torch.from_numpy(logS)\n",
    "  logS_delta = torch.from_numpy(logS_delta)\n",
    "  logS_ddelta = torch.from_numpy(logS_ddelta)\n",
    "  logS, logS_delta, logS_ddelta = normalize_mel(logS), normalize_mel(logS_delta), normalize_mel(logS_ddelta)\n",
    "\n",
    "  # Zero-padding\n",
    "  desired_shape = (128, 420)\n",
    "  padding_size = desired_shape[1] - logS.shape[1]\n",
    "  logS = torch.nn.functional.pad(logS, (0, padding_size))\n",
    "  logS_delta = torch.nn.functional.pad(logS_delta, (0, padding_size),value=1)\n",
    "  logS_ddelta = torch.nn.functional.pad(logS_ddelta, (0, padding_size),value=1)\n",
    "\n",
    "  return  torch.stack([logS, logS_delta, logS_ddelta], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c888a99a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# draw_mel() draws a spectrogram\n",
    "def draw_mel(S : Union[np.ndarray, torch.Tensor]) -> None:\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(np.float32(logS), x_axis='time', y_axis='mel', sr = sr)\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Mel-Spectrogram')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "150b5721",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_transform() converts data into a log mel-spectrogram\n",
    "def df_transform(df : pd.DataFrame, multi_channel : bool = False, random_seed : int = random_seed) -> pd.DataFrame:\n",
    "    if (multi_channel): df['Path'] = df['Path'].apply(lambda x: multi_mel_spec(x))\n",
    "    else: df['Path'] = df['Path'].apply(lambda x: mel_spec(x))\n",
    "\n",
    "    df['Emotion'] = df['Emotion'].apply(lambda x: int(invert_emotions[x]) - 1)\n",
    "    df['ID'] = df['ID'].apply(lambda x: int(x))\n",
    "    df = df.sample(frac=1, random_state = random_seed)\n",
    "    return df\n",
    "\n",
    "mel = df_transform(df)\n",
    "generated_mel = df_transform(generated_df)\n",
    "concat_mel = pd.concat([mel, generated_mel])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bb4868",
   "metadata": {},
   "source": [
    "**Transform**\n",
    "\n",
    "1. 기존 데이터를 PIL Image로 변환\n",
    "2. (128, 256)으로 Resize를 진행\n",
    "3. 다시 Tensor로 변환\n",
    "\n",
    "제로패딩할시 사용하지않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae2ac41b-2abe-47a1-958b-b2280eaa48a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Doesn't need to use if zero-padded\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(size=(128, 256)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04c0cb0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RAVDESS_Dataset(Dataset):\n",
    "  def __init__(self, x : pd.Series, y : pd.Series, transform):\n",
    "    self.emotion = y.to_list()\n",
    "    self.path = x.to_list()\n",
    "    self.transform = transform\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.emotion)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    spec = self.transform(self.path[idx])\n",
    "    y = self.emotion[idx]\n",
    "    return spec, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e7b7c14-494e-4a62-a777-8a2efeeb62a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prepare_dataloader() returns torch train/test(valid) DataLoaders\n",
    "def prepare_dataloader(train : pd.DataFrame, valid : pd.DataFrame, batch_size : int, seed : int = random_seed):\n",
    "\n",
    "  train_dataset = RAVDESS_Dataset(train['Path'], train['Emotion'], data_transform)\n",
    "  test_dataset = RAVDESS_Dataset(valid['Path'], valid['Emotion'], data_transform)\n",
    "\n",
    "  train_sampler = RandomSampler(train_dataset, generator=torch.Generator().manual_seed(seed))\n",
    "  test_sampler = RandomSampler(test_dataset, generator=torch.Generator().manual_seed(seed))\n",
    "\n",
    "  train_dataloader = DataLoader(train_dataset, batch_size = batch_size, sampler = train_sampler)\n",
    "  test_dataloader = DataLoader(test_dataset, batch_size = batch_size, sampler = test_sampler)\n",
    "\n",
    "  return train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e75af1d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9fe585",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226247ba",
   "metadata": {},
   "source": [
    "##### U-vector attention: [Attention Based Fully Convolutional Network forSpeech Emotion Recognition](https://arxiv.org/abs/1806.01506)\n",
    "\n",
    "**특징**\n",
    "\n",
    "![Alt text](image.png)\n",
    "- Lambda값은 0-1의 값을 가질수있음. 값 *0.3* 사용\n",
    "\n",
    "- Xavier Uniform Initialization을 사용하여 임의에 U vecotr를 생성\n",
    "    - Xavier Normal Initialization\n",
    "    - Zero Initialization\n",
    "    등도 사용가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47d5ac35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "  def __init__(self, num_features : int):\n",
    "    super().__init__()\n",
    "    self.dense = nn.Linear(in_features = num_features, out_features = num_features)\n",
    "    self.lamb_val = 0.3\n",
    "    self.u = nn.init.xavier_uniform_(nn.Parameter(torch.randn(1, num_features), requires_grad=True))\n",
    "    self.tanh = nn.Tanh()\n",
    "    \n",
    "  def forward(self, x : torch.Tensor) -> torch.Tensor:\n",
    "    batch_size, channel_size, variable_length = x.size()\n",
    "    x = torch.transpose(x, -1, -2)\n",
    "    e = self.tanh(self.dense(x))\n",
    "    e = self.u @ e.transpose(-1,-2) * self.lamb_val\n",
    "    a = torch.softmax(e, dim=-1)\n",
    "    out = a @ x\n",
    "    out = out.transpose(-1, -2)\n",
    "    output = torch.sum(out, dim=2)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4977da29",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7611d736",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### CNN14 : [PANNs: Large-Scale Pretrained Audio Neural Networks for Audio Pattern Recognition](https://arxiv.org/pdf/1912.10211.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2a33bf",
   "metadata": {},
   "source": [
    "**특징**\n",
    "- VGG-ish Network\n",
    "\n",
    "- Max Pooling 대신 Average Pooling 사용\n",
    "\n",
    "- 타 오디오셋에서 먼저 트레이닝후 Fine-tune\n",
    "\n",
    "\n",
    "**논문결과 (RAVDESS)**\n",
    "\n",
    "|          | Scratch | Fine-tune |\n",
    "| -------- | ------- | --------- |\n",
    "| Accuracy | 69.2%   | 72.1%     |\n",
    "- Speaker간의 Independency를 지켜서 실험\n",
    "\n",
    "\n",
    "- Global Average Pooling을 대신하여 Attention Layer를 적용가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8a91894b-2f1d-49a5-b2ee-2997139fc0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels : int, out_channels : int):\n",
    "\n",
    "        super(ConvBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                              kernel_size=(3, 3), stride=(1, 1),\n",
    "                              padding=(1, 1), bias=False)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels,\n",
    "                              kernel_size=(3, 3), stride=(1, 1),\n",
    "                              padding=(1, 1), bias=False)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.avgpool = nn.AvgPool2d((2,2))\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x : torch.Tensor) -> torch.Tensor:\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.avgpool(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class CNN14(nn.Module):\n",
    "  def __init__(self, uattn : bool):\n",
    "    super().__init__()\n",
    "    self.conv_layer1 = ConvBlock(in_channels = 1, out_channels = 64)\n",
    "    self.conv_layer2 = ConvBlock(64, 128)\n",
    "    self.conv_layer3 = ConvBlock(128, 256)\n",
    "    self.conv_layer4 = ConvBlock(256, 512)\n",
    "    self.conv_layer5 = ConvBlock(512, 1024)\n",
    "    self.conv_layer6 = ConvBlock(1024, 2048)\n",
    "    self.glob_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "    self.fc_layer = nn.Sequential(\n",
    "                  nn.Linear(2048, 512),\n",
    "                  nn.ReLU()\n",
    "    )\n",
    "    \n",
    "    self.classifier = nn.Linear(512, 8)\n",
    "    self.flatten = nn.Flatten(start_dim=1)\n",
    "    self.attention = None\n",
    "    if (uattn):\n",
    "        self.attention = Attention(2048)\n",
    "        self.flatten = nn.Flatten(start_dim=2)\n",
    "\n",
    "  def forward(self, x : torch.Tensor) -> torch.Tensor:\n",
    "    x = self.conv_layer1(x)\n",
    "    x = self.conv_layer2(x)\n",
    "    x = self.conv_layer3(x)\n",
    "    x = self.conv_layer4(x)\n",
    "    x = self.conv_layer5(x)\n",
    "    x = self.conv_layer6(x)\n",
    "    if (self.attention is None):\n",
    "        x = self.glob_pool(x)\n",
    "        x = self.flatten(x)\n",
    "    \n",
    "    else:\n",
    "        x = self.flatten(x)\n",
    "        x = self.attention(x)\n",
    "        \n",
    "    x = self.fc_layer(x)\n",
    "    x = self.classifier(x)\n",
    "    return x\n",
    "\n",
    "model = CNN14(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194420f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### CNNX : [Shallow over Deep Neural Networks: A Empirical Analysis for Human Emotion Classification Using Audio Data](https://link.springer.com/chapter/10.1007/978-3-030-76736-5_13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5441c8c",
   "metadata": {},
   "source": [
    "**구조**\n",
    "|          Layer           | Depth |\n",
    "| :----------------------: | :---: |\n",
    "| 2D Conv (ReLU + Avgpool) |   8   |\n",
    "| 2D Conv (ReLU + Avgpool) |  16   |\n",
    "| 2D Conv (ReLU + Avgpool) |  32   |\n",
    "|         13440 FC         |   |\n",
    "|     2048 FC ||\n",
    "|            2048 FC            |       |\n",
    "\n",
    "- Shallow Neural Network로 단순하게 구성\n",
    "- Max Pooling 대신 Average Pooling을 사용\n",
    "\n",
    "**논문결과**\n",
    "\n",
    "|          | Scratch |\n",
    "| -------- | ------- | \n",
    "| Accuracy | 82.99%  |\n",
    "\n",
    "- 평가 기준이 명확하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab8448a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNNX(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.conv1 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3, 3)),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "\n",
    "    self.conv2 = nn.Sequential(\n",
    "        nn.Conv2d(8, 16, (3, 3)),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "\n",
    "    self.conv3 = nn.Sequential(\n",
    "        nn.Conv2d(16, 32, (3, 3)),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "\n",
    "    self.fc_layer1 = nn.Sequential(\n",
    "        nn.Linear(in_features = 13440, out_features = 2048),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "\n",
    "    self.fc_layer2 = nn.Sequential(\n",
    "        nn.Linear(2048, 2048),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "    self.fc_layer3 = nn.Linear(2048, 8)\n",
    "    self.avg_pool = nn.AvgPool2d((2, 2))\n",
    "    self.flatten = nn.Flatten(start_dim=1)\n",
    "    \n",
    "  def forward(self, x : torch.Tensor) -> torch.Tensor:\n",
    "    x = self.avg_pool(self.conv1(x))\n",
    "    x = self.avg_pool(self.conv2(x))\n",
    "    x = self.avg_pool(self.conv3(x))\n",
    "    x = self.flatten(x)\n",
    "    x = self.fc_layer1(x)\n",
    "    x = self.fc_layer2(x)\n",
    "    x = self.fc_layer3(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0027b6b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### 1DCNNLSTM : [A Hybrid CNN–LSTM Network for the Classification of Human Activities Based on Micro-Doppler Radar](https://ieeexplore.ieee.org/document/8978926)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7490de",
   "metadata": {},
   "source": [
    "**구조**\n",
    "\n",
    "|          Layer           | Width |\n",
    "| :----------------------: | :---: |\n",
    "| 1D Conv (ReLU + Maxpool) |  64   |\n",
    "| 1D Conv (ReLU + Maxpool) |  128  |\n",
    "| 1D Conv (ReLU + Maxpool) |  256  |\n",
    "|           LSTM           |  256  |\n",
    "|            256 FC            |   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a6ac6de4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNNLSTM(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.conv_layer1 = nn.Sequential(\n",
    "        nn.Conv1d(128, 64, 3),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "    self.conv_layer2 = nn.Sequential(\n",
    "        nn.Conv1d(64, 128, 3),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "    self.conv_layer3 = nn.Sequential(\n",
    "        nn.Conv1d(128, 256, 3),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "    self.LSTM = nn.LSTM(256, 256, batch_first=True)\n",
    "    self.maxpool = nn.MaxPool1d(2)\n",
    "    self.classifier = nn.Linear(256, 8)\n",
    "\n",
    "  def forward(self, x : torch.Tensor) -> torch.Tensor:\n",
    "    x = x.squeeze(1)\n",
    "    x = self.conv_layer1(x)\n",
    "    x = self.maxpool(x)\n",
    "    x = self.conv_layer2(x)\n",
    "    x = self.maxpool(x)\n",
    "    x = self.conv_layer3(x)\n",
    "    x = x.transpose(1, 2)\n",
    "    x, (h0, c0) = self.LSTM(x)\n",
    "    x = self.classifier(h0[-1])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e4b46d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Fine-tune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13803cbd",
   "metadata": {},
   "source": [
    "- 이미 만들어진 구조와 Pretrained Weight값을 사용\n",
    "\n",
    "- 1채널 텐서를 입력받을수 있게 레이어를 추가 혹은 변경\n",
    "\n",
    "- Task에 맞게 마지막 레이어를 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158f129e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### ResNet 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "557d2b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mllab/anaconda3/envs/speech/lib/python3.9/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n",
      "/home/mllab/anaconda3/envs/speech/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, pretrained : bool = True):\n",
    "        super().__init__()\n",
    "        self.network = torchvision.models.resnet18(pretrained)\n",
    "\n",
    "        # Change # of in_channels\n",
    "        self.network.conv1 = nn.Conv2d(in_channels = 1, out_channels = self.network.conv1.out_channels,\n",
    "                                        kernel_size=7, stride=2, padding=3)\n",
    "\n",
    "        self.network.fc = nn.Linear(in_features = self.network.fc.in_features, out_features = 512)\n",
    "        self.classifier = nn.Linear(512, 8)\n",
    "\n",
    "\n",
    "    def forward(self, x : torch.Tensor) -> torch.Tensor:\n",
    "        x = self.network(x)\n",
    "        x = self.network.fc(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = ResNet18()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14673971",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### VGG19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cd4449",
   "metadata": {},
   "source": [
    "- Batch Normalization이 적용되어있음\n",
    "\n",
    "- Global Average Pooling 대신 Attention 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fbb263b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VGG19(nn.Module):\n",
    "  def __init__(self, pretrained : bool = True):\n",
    "    super().__init__()\n",
    "    self.network = torchvision.models.vgg19_bn(pretrained)\n",
    "\n",
    "    # Add one layer that takes one channel input\n",
    "    first_conv_layer = [nn.Conv2d(in_channels = 1, out_channels = 3, \n",
    "                                  kernel_size = 3, stride = 1, \n",
    "                                  padding = 1, dilation = 1, \n",
    "                                  groups = 1, bias=True)]\n",
    "                            \n",
    "    first_conv_layer.extend(list(self.network.features))  \n",
    "    self.network.features= nn.Sequential(*first_conv_layer)\n",
    "    \n",
    "    self.classifier = nn.Linear(512, 8)\n",
    "    self.attention = Attention(512)\n",
    "    self.flatten = nn.Flatten(start_dim = 2)\n",
    "    \n",
    "  def forward(self, x : torch.Tensor) -> torch.Tensor:\n",
    "    x = self.network.features(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.attention(x)\n",
    "    x = self.classifier(x)\n",
    "    return x\n",
    "\n",
    "model = VGG19()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f005afc",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d43b57",
   "metadata": {},
   "source": [
    "\n",
    "- Global Average Pooling 대신 Attention 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a480f08-ce64-4dce-a9d0-2c07b1c599c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mllab/anaconda3/envs/speech/lib/python3.9/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n",
      "/home/mllab/anaconda3/envs/speech/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, pretrained : bool = True):\n",
    "        super().__init__()\n",
    "        self.network = torchvision.models.alexnet(pretrained)\n",
    "        \n",
    "        first_conv_layer = [nn.Conv2d(in_channels = 1, out_channels = 3, \n",
    "                                  kernel_size = 3, stride = 1, \n",
    "                                  padding = 1, dilation = 1, \n",
    "                                  groups = 1, bias=True)]\n",
    "        \n",
    "        first_conv_layer.extend(list(self.network.features))  \n",
    "        self.network.features = nn.Sequential(*first_conv_layer)\n",
    "        \n",
    "        self.flatten = nn.Flatten(start_dim = 2)\n",
    "        self.avgpool  = self.network.avgpool\n",
    "        self.classifier = nn.Linear(256, 8)\n",
    "        self.attention = Attention(256)\n",
    "\n",
    "\n",
    "    def forward(self, x : torch.Tensor) -> torch.Tensor:\n",
    "        x = self.network.features(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.attention(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = AlexNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5feb3d",
   "metadata": {},
   "source": [
    "## Train & Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5e63d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TrainUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5917582-8550-4774-80e4-e0d00429dabe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cal_avg() returns accuracy, recall, f1-score, and precision scores\n",
    "def cal_avg(l : dict) -> float:\n",
    "  Accuracy = 0\n",
    "  Recall = 0\n",
    "  F1Score = 0\n",
    "  Precision = 0\n",
    "  support = 0\n",
    "\n",
    "  for report in l:\n",
    "    support += 1\n",
    "    Accuracy += report['accuracy']\n",
    "    Recall += report['macro avg']['recall']\n",
    "    F1Score += report['macro avg']['f1-score']\n",
    "    Precision += report['macro avg']['precision']\n",
    "\n",
    "    print(f\" Fold {support}: Accuracy : {round(report['accuracy'], 4)} Precision : {round(report['macro avg']['precision'],4)} Recall : {round(report['macro avg']['recall'], 4)} F1-Score : {round(report['macro avg']['f1-score'],4)}\")\n",
    "\n",
    "  Accuracy /= support\n",
    "  Recall /= support\n",
    "  F1Score /= support\n",
    "  Precision /= support\n",
    "  \n",
    "  return round(Accuracy, 4), round(Recall, 4), round(F1Score, 4), round(Precision, 4)\n",
    "\n",
    "\n",
    "# accuracy() returns the accuracy of the predicted label(s) compared to the true label(s)\n",
    "def accuracy(y_pred : torch.Tensor, y_true : torch.Tensor) -> float:\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc\n",
    "\n",
    "\n",
    "# train_step() trains the model\n",
    "def train_step(model, dataloader, optim, loss_fn, accuracy_fn) -> float:\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        y_logits = model(X)\n",
    "        y_preds = torch.log_softmax(y_logits, dim=1).argmax(dim=1)\n",
    "\n",
    "        acc = accuracy_fn(y_preds, y)\n",
    "        loss = loss_fn(y_logits, y)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_acc += acc\n",
    "\n",
    "    train_loss /= len(dataloader)\n",
    "    train_acc /= len(dataloader)\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "# eval_step() evalutes the model\n",
    "def eval_step(model, dataloader, optim, loss_fn, accuracy_fn) -> float:\n",
    "    test_loss = 0.0\n",
    "    test_acc = 0.0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for b, (X, y) in enumerate(dataloader):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_logits = model(X)\n",
    "            y_preds = torch.log_softmax(y_logits, dim=1).argmax(dim=1)\n",
    "\n",
    "            acc = accuracy_fn(y_preds, y)\n",
    "            loss = loss_fn(y_logits, y)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            test_acc += acc\n",
    "    test_loss /= len(dataloader)\n",
    "    test_acc /= len(dataloader)\n",
    "    print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")\n",
    "    return test_loss\n",
    "\n",
    "\n",
    "# report() returns the classification report in a dictionary format evluating the given model\n",
    "def report(model, dataloader) -> dict:\n",
    "  model.eval()\n",
    "  y_true=[]\n",
    "  y_pred=[]\n",
    "  labels = ['Neutral','Calm','Happy','Sad','Angry','Fearful','Disgust','Surprised']\n",
    "\n",
    "  with torch.inference_mode():\n",
    "      for b, (X, y) in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        y_logits = model(X)\n",
    "        y_preds = torch.softmax(y_logits, dim=1).argmax(dim=1)\n",
    "        y_true.append(y.cpu())\n",
    "        y_pred.append(y_preds.cpu())\n",
    "\n",
    "  true = np.concatenate(y_true)\n",
    "  pred = np.concatenate(y_pred)\n",
    "  print(classification_report(true, pred, digits=4))\n",
    "  return classification_report(true, pred, digits=4, output_dict = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f65f53",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a29745",
   "metadata": {},
   "source": [
    "More info @ /home/mllab/dchung/Notebook/config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72966c78-d305-4d2c-b1e9-6cf1031b2b6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "batch_size = 32\n",
    "learning_rate = 0.0001\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3e306f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f501b940",
   "metadata": {},
   "source": [
    "|              | Actor 1 | Actor2 | ...     | Actor k |\n",
    "| ------------ | ------- | ------ | ------- | ------- |\n",
    "| # of samples | 60      | 60     | k=1..24 | 60      |\n",
    "\n",
    "- Speaker Independence를 유지하기 위해 Actor의 ID를 기준으로 Train/Test(Valid)셋을 나눔\n",
    "\n",
    "    - 1 Fold : [4, 9, 10, 14, 15, 17] \n",
    "\n",
    "    - 2 Fold : [5, 13, 16, 18, 20, 23] \n",
    "\n",
    "    - 3 Fold : [1, 2, 6, 8, 19, 21] \n",
    "\n",
    "    - 4 Fold : [3, 7, 11, 12, 22, 24] \n",
    " \n",
    "*시드(351) 고정 필요*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73ffeacc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "actor = [x for x in range(1, 25)]\n",
    "k = 4\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state = 351) # fix this seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6f7248-cd55-4f7b-928f-be4c9dbcc1c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch 1 result:\n",
      "Train loss: 2.24100 | Train accuracy: 15.66%\n",
      "Test loss: 2.08737 | Test accuracy: 12.50%\n",
      "\n",
      "Epoch 2 result:\n",
      "Train loss: 2.01926 | Train accuracy: 20.37%\n",
      "Test loss: 1.99212 | Test accuracy: 20.05%\n",
      "\n",
      "Epoch 3 result:\n",
      "Train loss: 1.90029 | Train accuracy: 28.68%\n",
      "Test loss: 1.84139 | Test accuracy: 25.26%\n",
      "\n",
      "Epoch 4 result:\n",
      "Train loss: 1.74116 | Train accuracy: 35.02%\n",
      "Test loss: 1.73483 | Test accuracy: 34.38%\n",
      "\n",
      "Epoch 5 result:\n",
      "Train loss: 1.58140 | Train accuracy: 40.38%\n",
      "Test loss: 1.70163 | Test accuracy: 31.25%\n",
      "\n",
      "Epoch 6 result:\n",
      "Train loss: 1.42359 | Train accuracy: 47.76%\n",
      "Test loss: 1.73783 | Test accuracy: 36.20%\n",
      "\n",
      "Epoch 7 result:\n",
      "Train loss: 1.29815 | Train accuracy: 52.60%\n",
      "Test loss: 1.60573 | Test accuracy: 40.62%\n",
      "\n",
      "Epoch 8 result:\n",
      "Train loss: 1.15692 | Train accuracy: 59.28%\n",
      "Test loss: 1.63718 | Test accuracy: 41.93%\n",
      "\n",
      "Epoch 9 result:\n",
      "Train loss: 1.11185 | Train accuracy: 59.80%\n",
      "Test loss: 1.60250 | Test accuracy: 42.19%\n",
      "\n",
      "Epoch 10 result:\n",
      "Train loss: 1.02356 | Train accuracy: 64.43%\n",
      "Test loss: 1.62477 | Test accuracy: 44.27%\n",
      "\n",
      "Epoch 11 result:\n",
      "Train loss: 0.94201 | Train accuracy: 67.19%\n",
      "Test loss: 1.69573 | Test accuracy: 43.75%\n",
      "\n",
      "Epoch 12 result:\n",
      "Train loss: 0.81877 | Train accuracy: 72.55%\n",
      "Test loss: 1.61667 | Test accuracy: 44.27%\n",
      "\n",
      "Epoch 13 result:\n",
      "Train loss: 0.74085 | Train accuracy: 76.62%\n",
      "Test loss: 1.58537 | Test accuracy: 46.61%\n",
      "\n",
      "Epoch 14 result:\n",
      "Train loss: 0.70277 | Train accuracy: 76.93%\n",
      "Test loss: 1.55076 | Test accuracy: 45.05%\n",
      "\n",
      "Epoch 15 result:\n",
      "Train loss: 0.63582 | Train accuracy: 79.56%\n",
      "Test loss: 1.79267 | Test accuracy: 43.49%\n",
      "\n",
      "Epoch 16 result:\n",
      "Train loss: 0.64188 | Train accuracy: 77.76%\n",
      "Test loss: 1.64559 | Test accuracy: 44.53%\n",
      "\n",
      "Epoch 17 result:\n",
      "Train loss: 0.52663 | Train accuracy: 82.57%\n",
      "Test loss: 1.70666 | Test accuracy: 42.45%\n",
      "\n",
      "Epoch 18 result:\n",
      "Train loss: 0.44079 | Train accuracy: 87.04%\n",
      "Test loss: 2.02591 | Test accuracy: 40.36%\n",
      "\n",
      "Epoch 19 result:\n",
      "Train loss: 0.41550 | Train accuracy: 87.75%\n",
      "Test loss: 2.12039 | Test accuracy: 41.41%\n",
      "\n",
      "Epoch 20 result:\n",
      "Train loss: 0.39147 | Train accuracy: 88.60%\n",
      "Test loss: 1.82097 | Test accuracy: 46.61%\n",
      "\n",
      "Epoch 21 result:\n",
      "Train loss: 0.30976 | Train accuracy: 91.73%\n",
      "Test loss: 2.13402 | Test accuracy: 45.05%\n",
      "\n",
      "Epoch 22 result:\n",
      "Train loss: 0.32032 | Train accuracy: 90.23%\n",
      "Test loss: 2.10548 | Test accuracy: 43.49%\n",
      "\n",
      "Epoch 23 result:\n",
      "Train loss: 0.21667 | Train accuracy: 95.28%\n",
      "Test loss: 2.02816 | Test accuracy: 49.74%\n",
      "\n",
      "Epoch 24 result:\n",
      "Train loss: 0.23385 | Train accuracy: 93.32%\n",
      "Test loss: 2.07252 | Test accuracy: 47.92%\n",
      "\n",
      "Epoch 25 result:\n",
      "Train loss: 0.15660 | Train accuracy: 97.24%\n",
      "Test loss: 2.27134 | Test accuracy: 46.61%\n",
      "\n",
      "Epoch 26 result:\n",
      "Train loss: 0.14323 | Train accuracy: 97.03%\n",
      "Test loss: 2.31824 | Test accuracy: 48.44%\n",
      "\n",
      "Epoch 27 result:\n",
      "Train loss: 0.10679 | Train accuracy: 97.95%\n",
      "Test loss: 2.29432 | Test accuracy: 48.18%\n",
      "\n",
      "Epoch 28 result:\n",
      "Train loss: 0.11122 | Train accuracy: 97.33%\n",
      "Test loss: 2.42757 | Test accuracy: 46.88%\n",
      "\n",
      "Epoch 29 result:\n",
      "Train loss: 0.09608 | Train accuracy: 97.58%\n",
      "Test loss: 2.59854 | Test accuracy: 46.09%\n",
      "\n",
      "Epoch 30 result:\n",
      "Train loss: 0.07565 | Train accuracy: 98.99%\n",
      "Test loss: 2.33563 | Test accuracy: 50.00%\n",
      "\n",
      "Epoch 31 result:\n",
      "Train loss: 0.06016 | Train accuracy: 99.08%\n",
      "Test loss: 2.54634 | Test accuracy: 48.70%\n",
      "\n",
      "Epoch 32 result:\n",
      "Train loss: 0.04978 | Train accuracy: 99.36%\n",
      "Test loss: 2.55178 | Test accuracy: 47.66%\n",
      "\n",
      "Epoch 33 result:\n",
      "Train loss: 0.03965 | Train accuracy: 99.82%\n",
      "Test loss: 2.51040 | Test accuracy: 50.52%\n",
      "\n",
      "Epoch 34 result:\n",
      "Train loss: 0.03174 | Train accuracy: 99.82%\n",
      "Test loss: 2.69860 | Test accuracy: 48.18%\n",
      "\n",
      "Epoch 35 result:\n",
      "Train loss: 0.02387 | Train accuracy: 99.91%\n",
      "Test loss: 2.69133 | Test accuracy: 49.22%\n",
      "\n",
      "Epoch 36 result:\n",
      "Train loss: 0.01791 | Train accuracy: 100.00%\n",
      "Test loss: 2.79990 | Test accuracy: 48.18%\n",
      "\n",
      "Epoch 37 result:\n",
      "Train loss: 0.01721 | Train accuracy: 100.00%\n",
      "Test loss: 3.22555 | Test accuracy: 46.88%\n",
      "\n",
      "Epoch 38 result:\n",
      "Train loss: 0.01499 | Train accuracy: 100.00%\n",
      "Test loss: 2.79306 | Test accuracy: 50.52%\n",
      "\n",
      "Epoch 39 result:\n",
      "Train loss: 0.01368 | Train accuracy: 100.00%\n",
      "Test loss: 2.76937 | Test accuracy: 50.52%\n",
      "\n",
      "Epoch 40 result:\n",
      "Train loss: 0.01042 | Train accuracy: 100.00%\n",
      "Test loss: 3.03345 | Test accuracy: 47.14%\n",
      "\n",
      "Epoch 41 result:\n",
      "Train loss: 0.01253 | Train accuracy: 100.00%\n",
      "Test loss: 3.15893 | Test accuracy: 50.78%\n",
      "\n",
      "Epoch 42 result:\n",
      "Train loss: 0.02108 | Train accuracy: 99.82%\n",
      "Test loss: 2.93279 | Test accuracy: 51.04%\n",
      "\n",
      "Epoch 43 result:\n",
      "Train loss: 0.01625 | Train accuracy: 99.91%\n",
      "Test loss: 3.22679 | Test accuracy: 48.44%\n",
      "\n",
      "Epoch 44 result:\n",
      "Train loss: 0.00878 | Train accuracy: 100.00%\n",
      "Test loss: 3.04908 | Test accuracy: 49.22%\n",
      "\n",
      "Epoch 45 result:\n",
      "Train loss: 0.00568 | Train accuracy: 100.00%\n",
      "Test loss: 3.16199 | Test accuracy: 49.22%\n",
      "\n",
      "Epoch 46 result:\n",
      "Train loss: 0.00513 | Train accuracy: 100.00%\n",
      "Test loss: 3.15999 | Test accuracy: 48.96%\n",
      "\n",
      "Epoch 47 result:\n",
      "Train loss: 0.00599 | Train accuracy: 100.00%\n",
      "Test loss: 3.17001 | Test accuracy: 49.74%\n",
      "\n",
      "Epoch 48 result:\n",
      "Train loss: 0.00459 | Train accuracy: 100.00%\n",
      "Test loss: 3.25535 | Test accuracy: 49.22%\n",
      "\n",
      "Epoch 49 result:\n",
      "Train loss: 0.00400 | Train accuracy: 100.00%\n",
      "Test loss: 3.22391 | Test accuracy: 50.26%\n",
      "\n",
      "Epoch 50 result:\n",
      "Train loss: 0.00331 | Train accuracy: 100.00%\n",
      "Test loss: 3.28277 | Test accuracy: 50.26%\n",
      "\n",
      "Epoch 51 result:\n",
      "Train loss: 0.00315 | Train accuracy: 100.00%\n",
      "Test loss: 3.63256 | Test accuracy: 47.66%\n",
      "\n",
      "Epoch 52 result:\n",
      "Train loss: 0.00307 | Train accuracy: 100.00%\n",
      "Test loss: 3.45821 | Test accuracy: 47.14%\n",
      "\n",
      "Epoch 53 result:\n",
      "Train loss: 0.00313 | Train accuracy: 100.00%\n",
      "Test loss: 3.43993 | Test accuracy: 48.18%\n",
      "\n",
      "Epoch 54 result:\n",
      "Train loss: 0.00290 | Train accuracy: 100.00%\n",
      "Test loss: 3.59704 | Test accuracy: 50.52%\n",
      "\n",
      "Epoch 55 result:\n",
      "Train loss: 0.00256 | Train accuracy: 100.00%\n",
      "Test loss: 3.44357 | Test accuracy: 51.82%\n",
      "\n",
      "Epoch 56 result:\n",
      "Train loss: 0.00244 | Train accuracy: 100.00%\n",
      "Test loss: 3.53831 | Test accuracy: 50.26%\n",
      "\n",
      "Epoch 57 result:\n",
      "Train loss: 0.00213 | Train accuracy: 100.00%\n",
      "Test loss: 3.44942 | Test accuracy: 51.56%\n",
      "\n",
      "Epoch 58 result:\n",
      "Train loss: 0.00204 | Train accuracy: 100.00%\n",
      "Test loss: 3.71832 | Test accuracy: 50.00%\n",
      "\n",
      "Epoch 59 result:\n",
      "Train loss: 0.00179 | Train accuracy: 100.00%\n",
      "Test loss: 3.89626 | Test accuracy: 47.40%\n",
      "\n",
      "Epoch 60 result:\n",
      "Train loss: 0.00180 | Train accuracy: 100.00%\n",
      "Test loss: 3.60897 | Test accuracy: 50.52%\n",
      "\n",
      "Epoch 61 result:\n",
      "Train loss: 0.00173 | Train accuracy: 100.00%\n",
      "Test loss: 3.72882 | Test accuracy: 50.78%\n",
      "\n",
      "Epoch 62 result:\n",
      "Train loss: 0.00160 | Train accuracy: 100.00%\n",
      "Test loss: 3.80927 | Test accuracy: 47.92%\n",
      "\n",
      "Epoch 63 result:\n",
      "Train loss: 0.00159 | Train accuracy: 100.00%\n",
      "Test loss: 3.86452 | Test accuracy: 49.22%\n",
      "\n",
      "Epoch 64 result:\n",
      "Train loss: 0.00149 | Train accuracy: 100.00%\n",
      "Test loss: 3.63589 | Test accuracy: 50.78%\n",
      "\n",
      "Epoch 65 result:\n",
      "Train loss: 0.00140 | Train accuracy: 100.00%\n",
      "Test loss: 3.92479 | Test accuracy: 49.48%\n",
      "\n",
      "Epoch 66 result:\n",
      "Train loss: 0.00140 | Train accuracy: 100.00%\n",
      "Test loss: 3.77185 | Test accuracy: 51.30%\n",
      "\n",
      "Epoch 67 result:\n",
      "Train loss: 0.00128 | Train accuracy: 100.00%\n",
      "Test loss: 3.92510 | Test accuracy: 49.48%\n",
      "\n",
      "Epoch 68 result:\n",
      "Train loss: 0.00111 | Train accuracy: 100.00%\n",
      "Test loss: 4.08190 | Test accuracy: 48.70%\n",
      "\n",
      "Epoch 69 result:\n",
      "Train loss: 0.00106 | Train accuracy: 100.00%\n",
      "Test loss: 3.86514 | Test accuracy: 52.86%\n",
      "\n",
      "Epoch 70 result:\n",
      "Train loss: 0.00102 | Train accuracy: 100.00%\n",
      "Test loss: 3.94191 | Test accuracy: 50.26%\n",
      "\n",
      "Epoch 71 result:\n",
      "Train loss: 0.00093 | Train accuracy: 100.00%\n",
      "Test loss: 3.96015 | Test accuracy: 49.48%\n",
      "\n",
      "Epoch 72 result:\n",
      "Train loss: 0.00089 | Train accuracy: 100.00%\n",
      "Test loss: 4.07162 | Test accuracy: 49.22%\n",
      "\n",
      "Epoch 73 result:\n",
      "Train loss: 0.00084 | Train accuracy: 100.00%\n",
      "Test loss: 3.92276 | Test accuracy: 51.04%\n",
      "\n",
      "Epoch 74 result:\n",
      "Train loss: 0.00077 | Train accuracy: 100.00%\n",
      "Test loss: 4.00292 | Test accuracy: 52.08%\n",
      "\n",
      "Epoch 75 result:\n",
      "Train loss: 0.00076 | Train accuracy: 100.00%\n",
      "Test loss: 4.43321 | Test accuracy: 48.44%\n",
      "\n",
      "Epoch 76 result:\n",
      "Train loss: 0.00076 | Train accuracy: 100.00%\n",
      "Test loss: 3.91416 | Test accuracy: 50.52%\n",
      "\n",
      "Epoch 77 result:\n",
      "Train loss: 0.00071 | Train accuracy: 100.00%\n",
      "Test loss: 4.06253 | Test accuracy: 49.74%\n",
      "\n",
      "Epoch 78 result:\n",
      "Train loss: 0.00065 | Train accuracy: 100.00%\n",
      "Test loss: 4.05291 | Test accuracy: 50.26%\n",
      "\n",
      "Epoch 79 result:\n",
      "Train loss: 0.00062 | Train accuracy: 100.00%\n",
      "Test loss: 4.11618 | Test accuracy: 50.26%\n",
      "\n",
      "Epoch 80 result:\n",
      "Train loss: 0.00057 | Train accuracy: 100.00%\n",
      "Test loss: 4.40903 | Test accuracy: 47.92%\n",
      "\n",
      "Epoch 81 result:\n",
      "Train loss: 0.00056 | Train accuracy: 100.00%\n",
      "Test loss: 4.23778 | Test accuracy: 50.26%\n",
      "\n",
      "Epoch 82 result:\n",
      "Train loss: 0.00054 | Train accuracy: 100.00%\n",
      "Test loss: 4.05156 | Test accuracy: 52.34%\n",
      "\n",
      "Epoch 83 result:\n",
      "Train loss: 0.00051 | Train accuracy: 100.00%\n",
      "Test loss: 4.36981 | Test accuracy: 48.70%\n",
      "\n",
      "Epoch 84 result:\n",
      "Train loss: 0.00048 | Train accuracy: 100.00%\n",
      "Test loss: 4.15730 | Test accuracy: 49.74%\n",
      "\n",
      "Epoch 85 result:\n",
      "Train loss: 0.00046 | Train accuracy: 100.00%\n",
      "Test loss: 4.53586 | Test accuracy: 48.44%\n",
      "\n",
      "Epoch 86 result:\n",
      "Train loss: 0.00045 | Train accuracy: 100.00%\n",
      "Test loss: 4.13852 | Test accuracy: 51.04%\n",
      "\n",
      "Epoch 87 result:\n",
      "Train loss: 0.00044 | Train accuracy: 100.00%\n",
      "Test loss: 4.32751 | Test accuracy: 50.26%\n",
      "\n",
      "Epoch 88 result:\n",
      "Train loss: 0.00043 | Train accuracy: 100.00%\n",
      "Test loss: 4.54907 | Test accuracy: 49.48%\n",
      "\n",
      "Epoch 89 result:\n",
      "Train loss: 0.00040 | Train accuracy: 100.00%\n",
      "Test loss: 4.34478 | Test accuracy: 49.48%\n",
      "\n",
      "Epoch 90 result:\n",
      "Train loss: 0.00038 | Train accuracy: 100.00%\n",
      "Test loss: 4.33698 | Test accuracy: 50.26%\n",
      "\n",
      "Epoch 91 result:\n",
      "Train loss: 0.00037 | Train accuracy: 100.00%\n",
      "Test loss: 4.32938 | Test accuracy: 50.52%\n",
      "\n",
      "Epoch 92 result:\n",
      "Train loss: 0.00035 | Train accuracy: 100.00%\n",
      "Test loss: 4.65536 | Test accuracy: 47.92%\n",
      "\n",
      "Epoch 93 result:\n",
      "Train loss: 0.00035 | Train accuracy: 100.00%\n",
      "Test loss: 4.51066 | Test accuracy: 50.26%\n",
      "\n",
      "Epoch 94 result:\n",
      "Train loss: 0.00033 | Train accuracy: 100.00%\n",
      "Test loss: 4.50541 | Test accuracy: 49.74%\n",
      "\n",
      "Epoch 95 result:\n",
      "Train loss: 0.00033 | Train accuracy: 100.00%\n",
      "Test loss: 4.51466 | Test accuracy: 50.52%\n",
      "\n",
      "Epoch 96 result:\n",
      "Train loss: 0.00032 | Train accuracy: 100.00%\n",
      "Test loss: 4.77397 | Test accuracy: 48.70%\n",
      "\n",
      "Epoch 97 result:\n",
      "Train loss: 0.00030 | Train accuracy: 100.00%\n",
      "Test loss: 4.45249 | Test accuracy: 50.00%\n",
      "\n",
      "Epoch 98 result:\n",
      "Train loss: 0.00030 | Train accuracy: 100.00%\n",
      "Test loss: 4.53445 | Test accuracy: 48.96%\n",
      "\n",
      "Epoch 99 result:\n",
      "Train loss: 0.00029 | Train accuracy: 100.00%\n",
      "Test loss: 4.54303 | Test accuracy: 50.78%\n",
      "\n",
      "Epoch 100 result:\n",
      "Train loss: 0.00028 | Train accuracy: 100.00%\n",
      "Test loss: 4.69406 | Test accuracy: 48.44%\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3243    0.5000    0.3934        24\n",
      "           1     0.7778    0.4375    0.5600        48\n",
      "           2     0.4516    0.2917    0.3544        48\n",
      "           3     0.2857    0.4167    0.3390        48\n",
      "           4     0.7292    0.7292    0.7292        48\n",
      "           5     0.4035    0.4792    0.4381        48\n",
      "           6     0.8214    0.4792    0.6053        48\n",
      "           7     0.4677    0.6042    0.5273        48\n",
      "\n",
      "    accuracy                         0.4917       360\n",
      "   macro avg     0.5327    0.4922    0.4933       360\n",
      "weighted avg     0.5465    0.4917    0.5000       360\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch 1 result:\n",
      "Train loss: 2.09186 | Train accuracy: 13.48%\n",
      "Test loss: 2.05481 | Test accuracy: 12.76%\n",
      "\n",
      "Epoch 2 result:\n",
      "Train loss: 2.01909 | Train accuracy: 20.62%\n",
      "Test loss: 1.95654 | Test accuracy: 26.30%\n",
      "\n",
      "Epoch 3 result:\n",
      "Train loss: 1.86784 | Train accuracy: 29.20%\n",
      "Test loss: 1.91225 | Test accuracy: 28.91%\n",
      "\n",
      "Epoch 4 result:\n",
      "Train loss: 1.71170 | Train accuracy: 36.09%\n",
      "Test loss: 1.80814 | Test accuracy: 30.73%\n",
      "\n",
      "Epoch 5 result:\n",
      "Train loss: 1.52157 | Train accuracy: 44.76%\n",
      "Test loss: 1.71113 | Test accuracy: 34.90%\n",
      "\n",
      "Epoch 6 result:\n",
      "Train loss: 1.39770 | Train accuracy: 49.36%\n",
      "Test loss: 1.85622 | Test accuracy: 32.03%\n",
      "\n",
      "Epoch 7 result:\n",
      "Train loss: 1.29234 | Train accuracy: 52.67%\n",
      "Test loss: 1.60142 | Test accuracy: 46.09%\n",
      "\n",
      "Epoch 8 result:\n",
      "Train loss: 1.14082 | Train accuracy: 57.84%\n",
      "Test loss: 1.77293 | Test accuracy: 39.32%\n",
      "\n",
      "Epoch 9 result:\n",
      "Train loss: 1.04936 | Train accuracy: 61.95%\n",
      "Test loss: 1.55608 | Test accuracy: 46.35%\n",
      "\n",
      "Epoch 10 result:\n",
      "Train loss: 0.92180 | Train accuracy: 67.65%\n",
      "Test loss: 1.42872 | Test accuracy: 48.70%\n",
      "\n",
      "Epoch 11 result:\n",
      "Train loss: 0.84497 | Train accuracy: 70.59%\n",
      "Test loss: 1.48625 | Test accuracy: 49.74%\n",
      "\n",
      "Epoch 12 result:\n",
      "Train loss: 0.74585 | Train accuracy: 75.15%\n",
      "Test loss: 1.67068 | Test accuracy: 40.62%\n",
      "\n",
      "Epoch 13 result:\n",
      "Train loss: 0.67491 | Train accuracy: 78.00%\n",
      "Test loss: 1.52677 | Test accuracy: 51.56%\n",
      "\n",
      "Epoch 14 result:\n",
      "Train loss: 0.56009 | Train accuracy: 82.02%\n",
      "Test loss: 1.75045 | Test accuracy: 48.18%\n",
      "\n",
      "Epoch 15 result:\n",
      "Train loss: 0.53813 | Train accuracy: 83.06%\n",
      "Test loss: 1.59748 | Test accuracy: 52.08%\n",
      "\n",
      "Epoch 16 result:\n",
      "Train loss: 0.45674 | Train accuracy: 85.75%\n",
      "Test loss: 1.45645 | Test accuracy: 57.29%\n",
      "\n",
      "Epoch 17 result:\n",
      "Train loss: 0.36884 | Train accuracy: 88.85%\n",
      "Test loss: 1.57699 | Test accuracy: 59.90%\n",
      "\n",
      "Epoch 18 result:\n",
      "Train loss: 0.34428 | Train accuracy: 90.35%\n",
      "Test loss: 1.77462 | Test accuracy: 54.43%\n",
      "\n",
      "Epoch 19 result:\n",
      "Train loss: 0.27598 | Train accuracy: 91.85%\n",
      "Test loss: 1.86734 | Test accuracy: 51.30%\n",
      "\n",
      "Epoch 20 result:\n",
      "Train loss: 0.27415 | Train accuracy: 92.34%\n",
      "Test loss: 1.65928 | Test accuracy: 56.25%\n",
      "\n",
      "Epoch 21 result:\n",
      "Train loss: 0.23245 | Train accuracy: 93.08%\n",
      "Test loss: 1.69427 | Test accuracy: 57.03%\n",
      "\n",
      "Epoch 22 result:\n",
      "Train loss: 0.15759 | Train accuracy: 95.93%\n",
      "Test loss: 1.95913 | Test accuracy: 53.91%\n",
      "\n",
      "Epoch 23 result:\n",
      "Train loss: 0.13195 | Train accuracy: 97.86%\n",
      "Test loss: 1.99774 | Test accuracy: 55.47%\n",
      "\n",
      "Epoch 24 result:\n",
      "Train loss: 0.09609 | Train accuracy: 98.25%\n",
      "Test loss: 1.99935 | Test accuracy: 53.12%\n",
      "\n",
      "Epoch 25 result:\n",
      "Train loss: 0.08811 | Train accuracy: 98.44%\n",
      "Test loss: 1.85159 | Test accuracy: 57.81%\n",
      "\n",
      "Epoch 26 result:\n",
      "Train loss: 0.06519 | Train accuracy: 99.54%\n",
      "Test loss: 2.12210 | Test accuracy: 57.55%\n",
      "\n",
      "Epoch 27 result:\n",
      "Train loss: 0.05402 | Train accuracy: 99.60%\n",
      "Test loss: 2.23437 | Test accuracy: 53.65%\n",
      "\n",
      "Epoch 28 result:\n",
      "Train loss: 0.04339 | Train accuracy: 99.45%\n",
      "Test loss: 2.31999 | Test accuracy: 53.39%\n",
      "\n",
      "Epoch 29 result:\n",
      "Train loss: 0.03823 | Train accuracy: 99.82%\n",
      "Test loss: 2.45456 | Test accuracy: 52.60%\n",
      "\n",
      "Epoch 30 result:\n",
      "Train loss: 0.03182 | Train accuracy: 99.72%\n",
      "Test loss: 2.25985 | Test accuracy: 58.85%\n",
      "\n",
      "Epoch 31 result:\n",
      "Train loss: 0.02258 | Train accuracy: 99.82%\n",
      "Test loss: 2.58161 | Test accuracy: 54.43%\n",
      "\n",
      "Epoch 32 result:\n",
      "Train loss: 0.02183 | Train accuracy: 100.00%\n",
      "Test loss: 2.41867 | Test accuracy: 55.47%\n",
      "\n",
      "Epoch 33 result:\n",
      "Train loss: 0.01589 | Train accuracy: 100.00%\n",
      "Test loss: 2.40077 | Test accuracy: 55.21%\n",
      "\n",
      "Epoch 34 result:\n",
      "Train loss: 0.01468 | Train accuracy: 100.00%\n",
      "Test loss: 2.80554 | Test accuracy: 53.91%\n",
      "\n",
      "Epoch 35 result:\n",
      "Train loss: 0.01167 | Train accuracy: 100.00%\n",
      "Test loss: 2.48390 | Test accuracy: 54.43%\n",
      "\n",
      "Epoch 36 result:\n",
      "Train loss: 0.01029 | Train accuracy: 100.00%\n",
      "Test loss: 2.74251 | Test accuracy: 52.86%\n",
      "\n",
      "Epoch 37 result:\n",
      "Train loss: 0.00963 | Train accuracy: 100.00%\n",
      "Test loss: 2.38366 | Test accuracy: 59.11%\n",
      "\n",
      "Epoch 38 result:\n",
      "Train loss: 0.00808 | Train accuracy: 100.00%\n",
      "Test loss: 3.09157 | Test accuracy: 52.60%\n",
      "\n",
      "Epoch 39 result:\n",
      "Train loss: 0.00999 | Train accuracy: 100.00%\n",
      "Test loss: 3.17403 | Test accuracy: 51.04%\n",
      "\n",
      "Epoch 40 result:\n",
      "Train loss: 0.00734 | Train accuracy: 100.00%\n",
      "Test loss: 2.72024 | Test accuracy: 55.21%\n",
      "\n",
      "Epoch 41 result:\n",
      "Train loss: 0.00657 | Train accuracy: 100.00%\n",
      "Test loss: 2.69446 | Test accuracy: 55.47%\n",
      "\n",
      "Epoch 42 result:\n",
      "Train loss: 0.00498 | Train accuracy: 100.00%\n",
      "Test loss: 2.82003 | Test accuracy: 53.65%\n",
      "\n",
      "Epoch 43 result:\n",
      "Train loss: 0.00463 | Train accuracy: 100.00%\n",
      "Test loss: 2.65872 | Test accuracy: 57.29%\n",
      "\n",
      "Epoch 44 result:\n",
      "Train loss: 0.00443 | Train accuracy: 100.00%\n",
      "Test loss: 2.82197 | Test accuracy: 56.51%\n",
      "\n",
      "Epoch 45 result:\n",
      "Train loss: 0.00379 | Train accuracy: 100.00%\n",
      "Test loss: 2.83532 | Test accuracy: 54.43%\n",
      "\n",
      "Epoch 46 result:\n",
      "Train loss: 0.00331 | Train accuracy: 100.00%\n",
      "Test loss: 3.04281 | Test accuracy: 53.39%\n",
      "\n",
      "Epoch 47 result:\n",
      "Train loss: 0.00319 | Train accuracy: 100.00%\n",
      "Test loss: 2.92022 | Test accuracy: 54.69%\n",
      "\n",
      "Epoch 48 result:\n",
      "Train loss: 0.00314 | Train accuracy: 100.00%\n",
      "Test loss: 2.87550 | Test accuracy: 56.51%\n",
      "\n",
      "Epoch 49 result:\n",
      "Train loss: 0.00269 | Train accuracy: 100.00%\n",
      "Test loss: 2.94754 | Test accuracy: 54.95%\n",
      "\n",
      "Epoch 50 result:\n",
      "Train loss: 0.00273 | Train accuracy: 100.00%\n",
      "Test loss: 2.96340 | Test accuracy: 57.29%\n",
      "\n",
      "Epoch 51 result:\n",
      "Train loss: 0.00247 | Train accuracy: 100.00%\n",
      "Test loss: 3.00618 | Test accuracy: 56.51%\n",
      "\n",
      "Epoch 52 result:\n",
      "Train loss: 0.00229 | Train accuracy: 100.00%\n",
      "Test loss: 3.23505 | Test accuracy: 53.91%\n",
      "\n",
      "Epoch 53 result:\n",
      "Train loss: 0.00207 | Train accuracy: 100.00%\n",
      "Test loss: 3.07302 | Test accuracy: 56.25%\n",
      "\n",
      "Epoch 54 result:\n",
      "Train loss: 0.00189 | Train accuracy: 100.00%\n",
      "Test loss: 2.86715 | Test accuracy: 58.07%\n",
      "\n",
      "Epoch 55 result:\n",
      "Train loss: 0.00190 | Train accuracy: 100.00%\n",
      "Test loss: 3.12169 | Test accuracy: 55.47%\n",
      "\n",
      "Epoch 56 result:\n",
      "Train loss: 0.00194 | Train accuracy: 100.00%\n",
      "Test loss: 3.19425 | Test accuracy: 55.73%\n",
      "\n",
      "Epoch 57 result:\n",
      "Train loss: 0.00170 | Train accuracy: 100.00%\n",
      "Test loss: 3.02538 | Test accuracy: 55.99%\n",
      "\n",
      "Epoch 58 result:\n",
      "Train loss: 0.00156 | Train accuracy: 100.00%\n",
      "Test loss: 3.17712 | Test accuracy: 53.65%\n",
      "\n",
      "Epoch 59 result:\n",
      "Train loss: 0.00163 | Train accuracy: 100.00%\n",
      "Test loss: 3.11118 | Test accuracy: 55.73%\n",
      "\n",
      "Epoch 60 result:\n",
      "Train loss: 0.00141 | Train accuracy: 100.00%\n",
      "Test loss: 3.04106 | Test accuracy: 55.21%\n",
      "\n",
      "Epoch 61 result:\n",
      "Train loss: 0.00133 | Train accuracy: 100.00%\n",
      "Test loss: 3.18174 | Test accuracy: 55.21%\n",
      "\n",
      "Epoch 62 result:\n",
      "Train loss: 0.00135 | Train accuracy: 100.00%\n",
      "Test loss: 3.30601 | Test accuracy: 53.65%\n",
      "\n",
      "Epoch 63 result:\n",
      "Train loss: 0.00119 | Train accuracy: 100.00%\n",
      "Test loss: 3.17586 | Test accuracy: 55.21%\n",
      "\n",
      "Epoch 64 result:\n",
      "Train loss: 0.00115 | Train accuracy: 100.00%\n",
      "Test loss: 3.31412 | Test accuracy: 53.65%\n",
      "\n",
      "Epoch 65 result:\n",
      "Train loss: 0.00115 | Train accuracy: 100.00%\n",
      "Test loss: 3.40989 | Test accuracy: 55.47%\n",
      "\n",
      "Epoch 66 result:\n",
      "Train loss: 0.00104 | Train accuracy: 100.00%\n",
      "Test loss: 3.51752 | Test accuracy: 54.95%\n",
      "\n",
      "Epoch 67 result:\n",
      "Train loss: 0.00104 | Train accuracy: 100.00%\n",
      "Test loss: 3.39856 | Test accuracy: 55.47%\n",
      "\n",
      "Epoch 68 result:\n",
      "Train loss: 0.00097 | Train accuracy: 100.00%\n",
      "Test loss: 3.30832 | Test accuracy: 54.43%\n",
      "\n",
      "Epoch 69 result:\n",
      "Train loss: 0.00100 | Train accuracy: 100.00%\n",
      "Test loss: 3.30510 | Test accuracy: 55.73%\n",
      "\n",
      "Epoch 70 result:\n",
      "Train loss: 0.00093 | Train accuracy: 100.00%\n",
      "Test loss: 3.30303 | Test accuracy: 54.17%\n",
      "\n",
      "Epoch 71 result:\n",
      "Train loss: 0.00085 | Train accuracy: 100.00%\n",
      "Test loss: 3.30636 | Test accuracy: 55.47%\n",
      "\n",
      "Epoch 72 result:\n",
      "Train loss: 0.00081 | Train accuracy: 100.00%\n",
      "Test loss: 3.45243 | Test accuracy: 56.51%\n",
      "\n",
      "Epoch 73 result:\n",
      "Train loss: 0.00083 | Train accuracy: 100.00%\n",
      "Test loss: 3.79927 | Test accuracy: 51.82%\n",
      "\n",
      "Epoch 74 result:\n",
      "Train loss: 0.00078 | Train accuracy: 100.00%\n",
      "Test loss: 3.34653 | Test accuracy: 56.51%\n",
      "\n",
      "Epoch 75 result:\n",
      "Train loss: 0.00075 | Train accuracy: 100.00%\n",
      "Test loss: 3.28010 | Test accuracy: 54.17%\n",
      "\n",
      "Epoch 76 result:\n",
      "Train loss: 0.00073 | Train accuracy: 100.00%\n",
      "Test loss: 3.20452 | Test accuracy: 56.77%\n",
      "\n",
      "Epoch 77 result:\n",
      "Train loss: 0.00066 | Train accuracy: 100.00%\n",
      "Test loss: 3.68594 | Test accuracy: 53.65%\n",
      "\n",
      "Epoch 78 result:\n",
      "Train loss: 0.00064 | Train accuracy: 100.00%\n",
      "Test loss: 3.67533 | Test accuracy: 54.43%\n",
      "\n",
      "Epoch 79 result:\n",
      "Train loss: 0.00061 | Train accuracy: 100.00%\n",
      "Test loss: 3.47085 | Test accuracy: 54.17%\n",
      "\n",
      "Epoch 80 result:\n",
      "Train loss: 0.00059 | Train accuracy: 100.00%\n",
      "Test loss: 3.44507 | Test accuracy: 54.43%\n",
      "\n",
      "Epoch 81 result:\n",
      "Train loss: 0.00058 | Train accuracy: 100.00%\n",
      "Test loss: 3.36582 | Test accuracy: 53.91%\n",
      "\n",
      "Epoch 82 result:\n",
      "Train loss: 0.00055 | Train accuracy: 100.00%\n",
      "Test loss: 3.50444 | Test accuracy: 52.34%\n",
      "\n",
      "Epoch 83 result:\n",
      "Train loss: 0.00054 | Train accuracy: 100.00%\n",
      "Test loss: 3.32036 | Test accuracy: 55.99%\n",
      "\n",
      "Epoch 84 result:\n",
      "Train loss: 0.00051 | Train accuracy: 100.00%\n",
      "Test loss: 3.49211 | Test accuracy: 55.73%\n",
      "\n",
      "Epoch 85 result:\n",
      "Train loss: 0.00050 | Train accuracy: 100.00%\n",
      "Test loss: 3.72484 | Test accuracy: 53.39%\n",
      "\n",
      "Epoch 86 result:\n",
      "Train loss: 0.00046 | Train accuracy: 100.00%\n",
      "Test loss: 3.58163 | Test accuracy: 55.47%\n",
      "\n",
      "Epoch 87 result:\n",
      "Train loss: 0.00047 | Train accuracy: 100.00%\n",
      "Test loss: 3.46370 | Test accuracy: 54.95%\n",
      "\n",
      "Epoch 88 result:\n",
      "Train loss: 0.00045 | Train accuracy: 100.00%\n",
      "Test loss: 3.78581 | Test accuracy: 53.65%\n",
      "\n",
      "Epoch 89 result:\n",
      "Train loss: 0.00043 | Train accuracy: 100.00%\n",
      "Test loss: 3.50837 | Test accuracy: 55.21%\n",
      "\n",
      "Epoch 90 result:\n",
      "Train loss: 0.00042 | Train accuracy: 100.00%\n",
      "Test loss: 3.50848 | Test accuracy: 55.73%\n",
      "\n",
      "Epoch 91 result:\n",
      "Train loss: 0.00041 | Train accuracy: 100.00%\n",
      "Test loss: 3.51697 | Test accuracy: 55.21%\n",
      "\n",
      "Epoch 92 result:\n",
      "Train loss: 0.00041 | Train accuracy: 100.00%\n",
      "Test loss: 3.72266 | Test accuracy: 52.60%\n",
      "\n",
      "Epoch 93 result:\n",
      "Train loss: 0.00037 | Train accuracy: 100.00%\n",
      "Test loss: 3.60999 | Test accuracy: 54.43%\n",
      "\n",
      "Epoch 94 result:\n",
      "Train loss: 0.00036 | Train accuracy: 100.00%\n",
      "Test loss: 3.43993 | Test accuracy: 57.29%\n",
      "\n",
      "Epoch 95 result:\n",
      "Train loss: 0.00034 | Train accuracy: 100.00%\n",
      "Test loss: 3.50663 | Test accuracy: 56.25%\n",
      "\n",
      "Epoch 96 result:\n",
      "Train loss: 0.00034 | Train accuracy: 100.00%\n",
      "Test loss: 3.64255 | Test accuracy: 56.51%\n",
      "\n",
      "Epoch 97 result:\n",
      "Train loss: 0.00033 | Train accuracy: 100.00%\n",
      "Test loss: 3.98708 | Test accuracy: 54.43%\n",
      "\n",
      "Epoch 98 result:\n",
      "Train loss: 0.00033 | Train accuracy: 100.00%\n",
      "Test loss: 3.56892 | Test accuracy: 55.21%\n",
      "\n",
      "Epoch 99 result:\n",
      "Train loss: 0.00031 | Train accuracy: 100.00%\n",
      "Test loss: 3.49418 | Test accuracy: 56.51%\n",
      "\n",
      "Epoch 100 result:\n",
      "Train loss: 0.00029 | Train accuracy: 100.00%\n",
      "Test loss: 3.58279 | Test accuracy: 55.99%\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6111    0.4583    0.5238        24\n",
      "           1     0.8214    0.4792    0.6053        48\n",
      "           2     0.3519    0.3958    0.3725        48\n",
      "           3     0.6250    0.5208    0.5682        48\n",
      "           4     0.5306    0.5417    0.5361        48\n",
      "           5     0.6190    0.5417    0.5778        48\n",
      "           6     0.7600    0.7917    0.7755        48\n",
      "           7     0.3671    0.6042    0.4567        48\n",
      "\n",
      "    accuracy                         0.5472       360\n",
      "   macro avg     0.5858    0.5417    0.5520       360\n",
      "weighted avg     0.5841    0.5472    0.5539       360\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch 1 result:\n",
      "Train loss: 2.54352 | Train accuracy: 13.66%\n",
      "Test loss: 2.21684 | Test accuracy: 12.50%\n",
      "\n",
      "Epoch 2 result:\n",
      "Train loss: 2.02708 | Train accuracy: 19.85%\n",
      "Test loss: 1.95677 | Test accuracy: 24.48%\n",
      "\n",
      "Epoch 3 result:\n",
      "Train loss: 1.82754 | Train accuracy: 32.08%\n",
      "Test loss: 1.80846 | Test accuracy: 33.85%\n",
      "\n",
      "Epoch 4 result:\n",
      "Train loss: 1.66476 | Train accuracy: 39.40%\n",
      "Test loss: 1.76227 | Test accuracy: 33.59%\n",
      "\n",
      "Epoch 5 result:\n",
      "Train loss: 1.53413 | Train accuracy: 42.83%\n",
      "Test loss: 1.76392 | Test accuracy: 36.46%\n",
      "\n",
      "Epoch 6 result:\n",
      "Train loss: 1.42895 | Train accuracy: 48.31%\n",
      "Test loss: 1.52068 | Test accuracy: 46.35%\n",
      "\n",
      "Epoch 7 result:\n",
      "Train loss: 1.25931 | Train accuracy: 52.91%\n",
      "Test loss: 1.58166 | Test accuracy: 40.10%\n",
      "\n",
      "Epoch 8 result:\n",
      "Train loss: 1.16250 | Train accuracy: 57.94%\n",
      "Test loss: 1.62715 | Test accuracy: 47.14%\n",
      "\n",
      "Epoch 9 result:\n",
      "Train loss: 1.10080 | Train accuracy: 60.78%\n",
      "Test loss: 1.54862 | Test accuracy: 48.96%\n",
      "\n",
      "Epoch 10 result:\n",
      "Train loss: 1.00057 | Train accuracy: 64.22%\n",
      "Test loss: 1.64254 | Test accuracy: 46.09%\n",
      "\n",
      "Epoch 11 result:\n",
      "Train loss: 0.85202 | Train accuracy: 72.21%\n",
      "Test loss: 1.62480 | Test accuracy: 47.66%\n",
      "\n",
      "Epoch 12 result:\n",
      "Train loss: 0.78211 | Train accuracy: 72.58%\n",
      "Test loss: 1.57638 | Test accuracy: 50.52%\n",
      "\n",
      "Epoch 13 result:\n",
      "Train loss: 0.72963 | Train accuracy: 74.14%\n",
      "Test loss: 1.82204 | Test accuracy: 44.01%\n",
      "\n",
      "Epoch 14 result:\n",
      "Train loss: 0.73250 | Train accuracy: 75.31%\n",
      "Test loss: 1.54551 | Test accuracy: 52.86%\n",
      "\n",
      "Epoch 15 result:\n",
      "Train loss: 0.56894 | Train accuracy: 82.20%\n",
      "Test loss: 1.55625 | Test accuracy: 52.08%\n",
      "\n",
      "Epoch 16 result:\n",
      "Train loss: 0.52045 | Train accuracy: 83.67%\n",
      "Test loss: 1.66133 | Test accuracy: 48.18%\n",
      "\n",
      "Epoch 17 result:\n",
      "Train loss: 0.47530 | Train accuracy: 83.82%\n",
      "Test loss: 1.71073 | Test accuracy: 48.70%\n",
      "\n",
      "Epoch 18 result:\n",
      "Train loss: 0.39791 | Train accuracy: 87.71%\n",
      "Test loss: 1.78406 | Test accuracy: 50.78%\n",
      "\n",
      "Epoch 19 result:\n",
      "Train loss: 0.36599 | Train accuracy: 88.76%\n",
      "Test loss: 2.10151 | Test accuracy: 43.75%\n",
      "\n",
      "Epoch 20 result:\n",
      "Train loss: 0.30508 | Train accuracy: 91.57%\n",
      "Test loss: 1.80754 | Test accuracy: 50.00%\n",
      "\n",
      "Epoch 21 result:\n",
      "Train loss: 0.32207 | Train accuracy: 89.34%\n",
      "Test loss: 1.71909 | Test accuracy: 53.91%\n",
      "\n",
      "Epoch 22 result:\n",
      "Train loss: 0.29425 | Train accuracy: 90.69%\n",
      "Test loss: 1.99930 | Test accuracy: 51.82%\n",
      "\n",
      "Epoch 23 result:\n",
      "Train loss: 0.20482 | Train accuracy: 95.22%\n",
      "Test loss: 1.84835 | Test accuracy: 55.21%\n",
      "\n",
      "Epoch 24 result:\n",
      "Train loss: 0.17943 | Train accuracy: 95.65%\n",
      "Test loss: 2.28850 | Test accuracy: 49.74%\n",
      "\n",
      "Epoch 25 result:\n",
      "Train loss: 0.17221 | Train accuracy: 95.77%\n",
      "Test loss: 1.90793 | Test accuracy: 54.69%\n",
      "\n",
      "Epoch 26 result:\n",
      "Train loss: 0.13501 | Train accuracy: 96.94%\n",
      "Test loss: 1.97860 | Test accuracy: 53.12%\n",
      "\n",
      "Epoch 27 result:\n",
      "Train loss: 0.11479 | Train accuracy: 97.49%\n",
      "Test loss: 2.14319 | Test accuracy: 54.17%\n",
      "\n",
      "Epoch 28 result:\n",
      "Train loss: 0.09114 | Train accuracy: 98.81%\n",
      "Test loss: 2.05977 | Test accuracy: 52.34%\n",
      "\n",
      "Epoch 29 result:\n",
      "Train loss: 0.06832 | Train accuracy: 99.36%\n",
      "Test loss: 2.21837 | Test accuracy: 52.34%\n",
      "\n",
      "Epoch 30 result:\n",
      "Train loss: 0.05872 | Train accuracy: 99.23%\n",
      "Test loss: 2.52881 | Test accuracy: 48.96%\n",
      "\n",
      "Epoch 31 result:\n",
      "Train loss: 0.06983 | Train accuracy: 98.90%\n",
      "Test loss: 2.47231 | Test accuracy: 50.00%\n",
      "\n",
      "Epoch 32 result:\n",
      "Train loss: 0.05677 | Train accuracy: 99.54%\n",
      "Test loss: 2.21750 | Test accuracy: 52.60%\n",
      "\n",
      "Epoch 33 result:\n",
      "Train loss: 0.03831 | Train accuracy: 99.91%\n",
      "Test loss: 2.64469 | Test accuracy: 50.78%\n",
      "\n",
      "Epoch 34 result:\n",
      "Train loss: 0.02624 | Train accuracy: 99.91%\n",
      "Test loss: 2.70000 | Test accuracy: 50.26%\n",
      "\n",
      "Epoch 35 result:\n",
      "Train loss: 0.02279 | Train accuracy: 99.91%\n",
      "Test loss: 2.73836 | Test accuracy: 52.60%\n",
      "\n",
      "Epoch 36 result:\n",
      "Train loss: 0.02482 | Train accuracy: 99.91%\n",
      "Test loss: 2.57296 | Test accuracy: 51.82%\n",
      "\n",
      "Epoch 37 result:\n",
      "Train loss: 0.02048 | Train accuracy: 100.00%\n",
      "Test loss: 2.61736 | Test accuracy: 51.04%\n",
      "\n",
      "Epoch 38 result:\n",
      "Train loss: 0.01541 | Train accuracy: 100.00%\n",
      "Test loss: 2.96752 | Test accuracy: 51.30%\n",
      "\n",
      "Epoch 39 result:\n",
      "Train loss: 0.01724 | Train accuracy: 100.00%\n",
      "Test loss: 2.60648 | Test accuracy: 52.08%\n",
      "\n",
      "Epoch 40 result:\n",
      "Train loss: 0.01066 | Train accuracy: 100.00%\n",
      "Test loss: 2.83789 | Test accuracy: 54.43%\n",
      "\n",
      "Epoch 41 result:\n",
      "Train loss: 0.00930 | Train accuracy: 100.00%\n",
      "Test loss: 2.71064 | Test accuracy: 54.95%\n",
      "\n",
      "Epoch 42 result:\n",
      "Train loss: 0.00819 | Train accuracy: 100.00%\n",
      "Test loss: 2.83026 | Test accuracy: 53.39%\n",
      "\n",
      "Epoch 43 result:\n",
      "Train loss: 0.00782 | Train accuracy: 100.00%\n",
      "Test loss: 3.02408 | Test accuracy: 50.52%\n",
      "\n",
      "Epoch 44 result:\n",
      "Train loss: 0.00731 | Train accuracy: 100.00%\n",
      "Test loss: 2.83300 | Test accuracy: 54.43%\n",
      "\n",
      "Epoch 45 result:\n",
      "Train loss: 0.00560 | Train accuracy: 100.00%\n",
      "Test loss: 2.98107 | Test accuracy: 53.12%\n",
      "\n",
      "Epoch 46 result:\n",
      "Train loss: 0.00552 | Train accuracy: 100.00%\n",
      "Test loss: 3.15502 | Test accuracy: 51.82%\n",
      "\n",
      "Epoch 47 result:\n",
      "Train loss: 0.00574 | Train accuracy: 100.00%\n",
      "Test loss: 2.95484 | Test accuracy: 51.56%\n",
      "\n",
      "Epoch 48 result:\n",
      "Train loss: 0.00474 | Train accuracy: 100.00%\n",
      "Test loss: 3.17573 | Test accuracy: 51.30%\n",
      "\n",
      "Epoch 49 result:\n",
      "Train loss: 0.00459 | Train accuracy: 100.00%\n",
      "Test loss: 2.98545 | Test accuracy: 52.34%\n",
      "\n",
      "Epoch 50 result:\n"
     ]
    }
   ],
   "source": [
    "dict_list = []\n",
    "k_train_acc = []\n",
    "k_test_acc = []\n",
    "k_train_loss = []\n",
    "k_test_loss =[]\n",
    "\n",
    "# KFold\n",
    "for i, (train_index, valid_index) in enumerate(kf.split(actor)):\n",
    "  \n",
    "    train_loss = []\n",
    "    test_loss =[]\n",
    "\n",
    "    print(f'FOLD {i + 1}')\n",
    "    print('--------------------------------')\n",
    "    train_actor, valid_actor = [actor[j] for j in train_index], [actor[j] for j in valid_index]\n",
    "    train = mel[mel['ID'].isin(train_actor)]\n",
    "    valid = mel[mel['ID'].isin(valid_actor)]\n",
    "\n",
    "    '''\n",
    "    normal, strong = valid[valid['Intensity'] == \"Normal\"], valid[valid['Intensity'] == \"Strong\"]\n",
    "\n",
    "    # Train Strong Test Normal\n",
    "    train = pd.concat([train, strong])\n",
    "    valid = normal\n",
    "\n",
    "    # Train Normal Test Strong\n",
    "    valid = pd.concat([strong, normal[normal['Emotion'] == 0]])\n",
    "    train = pd.concat([train, normal[normal['Emotion'] != 0]])\n",
    "    '''\n",
    "\n",
    "    \n",
    "    train_dataloader, test_dataloader = prepare_dataloader(train, valid, batch_size, random_seed)\n",
    "    model = CNNX()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.00001)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Train & Evaluate\n",
    "    for epoch in range(epochs):\n",
    "      print(f\"Epoch {epoch + 1} result:\")\n",
    "      train_result = train_step(model, train_dataloader, optimizer, criterion, accuracy)\n",
    "      test_result = eval_step(model, test_dataloader, optimizer, criterion, accuracy)\n",
    "      train_loss.append(train_result)\n",
    "      test_loss.append(test_result)\n",
    "\n",
    "\n",
    "    k_train_loss.append(train_loss)\n",
    "    k_test_loss.append(test_loss)\n",
    "    dict_list.append(report(model, test_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d96b5a",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf58744",
   "metadata": {},
   "source": [
    "- Macro Average를 사용\n",
    "    - Balanced Dataset이여서 Weighted Average와 Macro Average와 큰 차이없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8132296b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fold 1: Accuracy : 0.55 Precision : 0.5443 Recall : 0.5391 F1-Score : 0.5376\n",
      " Fold 2: Accuracy : 0.5417 Precision : 0.5435 Recall : 0.5365 F1-Score : 0.5288\n",
      " Fold 3: Accuracy : 0.5639 Precision : 0.5505 Recall : 0.5547 F1-Score : 0.5472\n",
      " Fold 4: Accuracy : 0.625 Precision : 0.6425 Recall : 0.6224 F1-Score : 0.6221\n",
      "---------------------------\n",
      "Accuracy : 57.010000000000005% \n",
      "Precision : 57.02% \n",
      "Recall : 56.32% \n",
      "F1-Score : 55.88999999999999%\n"
     ]
    }
   ],
   "source": [
    "accuracy, recall, f1, precision = cal_avg(dict_list)\n",
    "print(\"---------------------------\")\n",
    "print(f\"Accuracy : {accuracy * 100}% \\nPrecision : {precision * 100}% \\nRecall : {recall * 100}% \\nF1-Score : {f1 * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e26d32",
   "metadata": {},
   "source": [
    "Training from Scratch\n",
    "|               | Accuracy | Precision | Recall | F1-Score |\n",
    "| ------------- | -------- | --------- | ------ | -------- |\n",
    "| CNN-14        | 60.00%   | 66.28%    | 60.48% | 59.30%   |\n",
    "| CNN-14 + Attn | 60.68%   | 66.05%    | 61.14% | 60.20%   |\n",
    "| CNN-X         | 54.93%   | 57.43%    | 54.43% | 54.24%   |\n",
    "| 1DCNNLSTM     | 56.81%   | 56.98%    | 55.73% | 54.91%   |\n",
    "\n",
    "\n",
    "\n",
    "Fine-Tuning\n",
    "|                | Accuracy | Precision | Recall | F1-Score |\n",
    "| -------------- | -------- | --------- | ------ | -------- |\n",
    "| VGG19 + Attn   | 65.28%   | 66.42%    | 65.10% | 64.43%   |\n",
    "| ResNet         | 57.01%   | 57.02%    | 56.32% | 55.89%   |\n",
    "| AlexNet + Attn | 55.62%   | 55.24%    | 54.69% | 53.81%   |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAVDESS",
   "language": "python",
   "name": "ravdess"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
